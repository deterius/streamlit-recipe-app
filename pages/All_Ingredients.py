import streamlit as st
import shutil

st.set_page_config(page_title="é£Ÿææ•°æ®åº“", layout="centered")

import pandas as pd
import os
from datetime import datetime
import unicodedata #for weChat pasting
import datetime
from helper_functions import compute_unit_cost, clean_ingredient_df

# File Name for database
DATA_FILE = "ingredients.csv"
RECIPE_FILE = "recipes.json"

# Column names (in Chinese)
COLUMNS = [
    "ç¼–å·",          # Reference Number
    "ä¾›åº”å•†",        # Supplier
    "é£Ÿæè‹±æ–‡å",    # Ingredient En
    "é£Ÿæä¸­æ–‡å",    # Ingredient ZH
    "é£Ÿæåˆ†ç±»",      # Type
    "å•ä½",          # Unit
    "å•ä½ä»·æ ¼",      # Cost per Unit
    "å•ä½å®¹é‡",      # Volume per Unit
    "åŸºç¡€å•ä½ä»·æ ¼",    # Base unit cost
    "åˆ›å»ºæ—¶é—´",      # Date Created
    "ä¿®æ”¹æ—¶é—´"       # Date Modified
]

# Category to prefix mapping
CATEGORY_PREFIX = {
    "æœªåŠ å·¥è‚‰ç±»": "RME",
    "åŠ å·¥è‚‰ç±»": "PME",
    "æµ·é²œç±»": "SEA",
    "å†»å“ç±»": "FRZ",
    "è°ƒå‘³å“": "CON",
    "å¹²è´§": "DRY",
    "è”¬èœ": "VEG",
    "é¢„åˆ¶å“": "PRE",
    "å¨æˆ¿ç”¨å“": "KTC"
}

# Create if no DB exists
if not os.path.exists(DATA_FILE):
    pd.DataFrame(columns=COLUMNS).to_csv(DATA_FILE, index=False)
    
# Load existing if exists
df = pd.read_csv(DATA_FILE)
df = clean_ingredient_df(df)

st.title("ğŸ¥¬ é£Ÿææ•°æ®åº“")
st.markdown("Rourou Nanshan")

st.subheader("ğŸ“‹ å½“å‰é£Ÿæåˆ—è¡¨")
# -- Filtering sidebar or inline
col1, col2 = st.columns(2)
with col1:
    selected_type = st.selectbox("ç­›é€‰ï¼šæŒ‰é£Ÿæåˆ†ç±»", ["å…¨éƒ¨"] + list(CATEGORY_PREFIX.keys()))
with col2:
    search_text = st.text_input("æœç´¢é£Ÿæï¼ˆä¸­è‹±æ–‡ï¼‰")

# -- Apply filters to DF
filtered_df = df.copy()
if selected_type != "å…¨éƒ¨":
    filtered_df = filtered_df[filtered_df["é£Ÿæåˆ†ç±»"] == selected_type]
    
# Strip everything from the search and make sure its compatiable with WeChat
search_text = unicodedata.normalize("NFKC", search_text.strip())

if search_text:
    filtered_df = filtered_df[
        filtered_df["é£Ÿæä¸­æ–‡å"].astype(str).str.contains(search_text, case=False, na=False) |
        filtered_df["é£Ÿæè‹±æ–‡å"].astype(str).str.contains(search_text, case=False, na=False)
    ]

# Make sure creation time column is present   
if "åˆ›å»ºæ—¶é—´" not in filtered_df.columns:
    filtered_df["åˆ›å»ºæ—¶é—´"] = ""
    
# -- Show More recent first 
filtered_df = filtered_df.sort_values("åˆ›å»ºæ—¶é—´", ascending=False)
display_df = filtered_df.drop(columns=["åˆ›å»ºæ—¶é—´"])

edited_df = st.data_editor(
    display_df,
    use_container_width=True,
    num_rows="dynamic",
    key="editable_ingredients",
    column_config={
        "ç¼–å·": st.column_config.TextColumn("ç¼–å·", disabled=True),
        # "å•ä½ä»·æ ¼": st.column_config.NumberColumn("å•ä½ä»·æ ¼", disabled=True),
        "åˆ›å»ºæ—¶é—´": st.column_config.TextColumn("åˆ›å»ºæ—¶é—´", disabled=True),
        "ä¿®æ”¹æ—¶é—´": st.column_config.TextColumn("ä¿®æ”¹æ—¶é—´", disabled=True),
    }
)
if st.button("ğŸ’¾ ä¿å­˜ä¿®æ”¹"):
    now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    # Create a copy of the full DataFrame to modify
    df_updated = df.copy()

    for i, row in edited_df.iterrows():
        serial = row["ç¼–å·"]
        full_idx = df[df["ç¼–å·"] == serial].index
        if not full_idx.empty:
            idx = full_idx[0]
            # Compare only editable columns
            for col in edited_df.columns:
                if col in ["åˆ›å»ºæ—¶é—´", "ä¿®æ”¹æ—¶é—´", "ç¼–å·", "åŸºç¡€å•ä½ä»·æ ¼"]:
                    continue
                if pd.isna(row[col]) and pd.isna(df.at[idx, col]):
                    continue
                if row[col] != df.at[idx, col]:
                    df_updated.at[idx, col] = row[col]
                    df_updated.at[idx, "ä¿®æ”¹æ—¶é—´"] = now
                    
    # ğŸ” Backup before overwrite
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    os.makedirs("backups", exist_ok=True)
    backup_path = f"backups/ingredients_backup_{timestamp}.csv"
    shutil.copy(DATA_FILE, backup_path)
    # Backup path for recipes
    recipe_backup_path = f"backups/recipes_backup_{timestamp}.json"
    if os.path.exists(RECIPE_FILE):
        shutil.copy(RECIPE_FILE, recipe_backup_path)

    # Save the full dataset, not the filtered one
    df_updated.to_csv(DATA_FILE, index=False, encoding="utf-8-sig")
    st.success("âœ… ä¿®æ”¹å·²ä¿å­˜ï¼ˆå…¨è¡¨å·²æ›´æ–°ï¼‰")
    
    import json

    # --- Load updated ingredients ---
    ingredients_df = pd.read_csv(DATA_FILE)
    ingredients_df = clean_ingredient_df(ingredients_df)
    ingredient_map = {
        row["ç¼–å·"]: row for _, row in ingredients_df.iterrows()
    }

    # --- Load recipes ---
    with open(RECIPE_FILE, "r", encoding="utf-8") as f:
        recipes = json.load(f)

    # --- Update recipes ---
    now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    for recipe in recipes:
        updated_ingredients = []
        for item in recipe.get("é£Ÿæ", []):
            serial = item.get("ç¼–å·")
            ing = ingredient_map.get(serial)
            if ing is None:
                updated_ingredients.append(item)  # Ingredient not found in latest DB
                continue

            # Update cost & names
            item["åŸºç¡€å•ä½ä»·æ ¼"] = ing["åŸºç¡€å•ä½ä»·æ ¼"]
            item["æ€»æˆæœ¬"] = float(item.get("ç”¨é‡", 0)) * ing["åŸºç¡€å•ä½ä»·æ ¼"]
            item["é£Ÿæè‹±æ–‡å"] = ing.get("é£Ÿæè‹±æ–‡å", item.get("é£Ÿæè‹±æ–‡å", ""))
            item["é£Ÿæä¸­æ–‡å"] = ing.get("é£Ÿæä¸­æ–‡å", item.get("é£Ÿæä¸­æ–‡å", ""))
            updated_ingredients.append(item)

        # Update the recipe ingredient list
        recipe["é£Ÿæ"] = updated_ingredients

        # Update cost and percentage
        total_cost = sum(item["æ€»æˆæœ¬"] for item in updated_ingredients)
        recipe["æ€»æˆæœ¬"] = round(total_cost, 2)
        price = float(recipe.get("å”®ä»·", 0))
        recipe["æˆæœ¬ç™¾åˆ†æ¯”"] = round((total_cost / price) * 100, 2) if price else 0
        recipe["ä¿®æ”¹æ—¶é—´"] = now

    # --- Save updated recipes ---
    with open(RECIPE_FILE, "w", encoding="utf-8") as f:
        json.dump(recipes, f, ensure_ascii=False, indent=2)


